{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd62b82-6820-4e52-a811-8877ff92e58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44e75516-baea-4b46-b142-ddf988ed131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e697dc2-4a7f-4172-837a-8daf7864e435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['instance_date'] = df['instance_date'].str.replace('/', '-', regex=False)\n",
    "\n",
    "df['instance_date'] = pd.to_datetime(df['instance_date'], format='%d-%m-%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42a240dc-db6a-40a6-833e-0558cc95c1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['instance_date'] >= '2013-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "048885cd-b8ba-483f-b486-c46bef9bead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['rooms_en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "257cb38b-16b7-426c-8ba0-0fc7ab6a464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['property_type_en'] = df['property_type_en'].replace('Unit', 'Apartment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38a2cb2-eecb-45d1-8920-1bc96d3f3005",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['property_usage_en'].isin(['Hospitality', 'Storage'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff8680a-75cc-4fc7-b324-19e6e9f7be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['property_usage_en'].str.strip() != 'Hospitality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be86e326-d516-4cad-95db-d42341795caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_values = ['PENTHOUSE', 'Single Room', 'Store','GYM', '8 B/R', '9 B/R']\n",
    "\n",
    "# Step 3: Filter out rows that have these values in 'rooms_en'\n",
    "df = df[~df['rooms_en'].isin(drop_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b49bf1e-336e-4489-b119-6d48731b448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_values = ['1 B/R', '2 B/R', 'Studio', '3 B/R', 'Office', '4 B/R', '5 B/R', '6 B/R', '7 B/R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71dde800-af1c-4807-a3fd-86f0cffb8236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['rooms_en'].str.strip() != 'Shop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6802db41-fd3d-4f33-b576-5d5aab21964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rooms_en'] = df['rooms_en'].apply(lambda x: x if x in keep_values else 'Others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82b7465c-703b-4348-85a9-11d3e1fb3160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rooms_en\n",
       "1 B/R     217595\n",
       "2 B/R     156843\n",
       "Studio    112080\n",
       "3 B/R      93846\n",
       "4 B/R      31474\n",
       "Office     28358\n",
       "5 B/R       3119\n",
       "6 B/R        192\n",
       "7 B/R         29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rooms_frequency = df['rooms_en'].value_counts()\n",
    "rooms_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "090fb293-1228-4939-8b85-ea3f5f29cfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average procedure_area for each room type:\n",
      "rooms_en\n",
      "1 B/R       76.046924\n",
      "2 B/R      128.950931\n",
      "3 B/R      209.961288\n",
      "4 B/R      323.585627\n",
      "5 B/R      512.383094\n",
      "6 B/R     1055.768542\n",
      "7 B/R     1644.627586\n",
      "Office     132.826357\n",
      "Studio      42.342994\n",
      "Name: procedure_area, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "average_procedure_by_room = df.groupby('rooms_en')['procedure_area'].mean()\n",
    "\n",
    "# Display the average procedure area for each room type\n",
    "print(\"Average procedure_area for each room type:\")\n",
    "print(average_procedure_by_room)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76697621-12e9-4e23-8232-eb38840221e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique rooms_en values: ['Office' '1 B/R' '2 B/R' 'Studio' '3 B/R' '4 B/R' '5 B/R' '6 B/R' '7 B/R']\n",
      "Unique procedure_area values: [130.13 268.94  63.67 ... 275.28  12.75 362.74]\n",
      "Unique room_value values: [4 2 3 1 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "average_procedure_by_room = df.groupby('rooms_en')['procedure_area'].mean().reset_index()\n",
    "\n",
    "# Rank the room types based on their average procedure_area (smallest gets 1)\n",
    "average_procedure_by_room['room_value'] = average_procedure_by_room['procedure_area'].rank(method='dense', ascending=True).astype(int)\n",
    "\n",
    "# Merge the ranked values back into the original dataframe\n",
    "df = pd.merge(df, average_procedure_by_room[['rooms_en', 'room_value']], on='rooms_en', how='left')\n",
    "\n",
    "# Display the dataframe with room values assigned\n",
    "# df[['rooms_en', 'procedure_area', 'room_value']].head(15)\n",
    "# df[['rooms_en', 'procedure_area', 'room_value']].drop_duplicates()\n",
    "\n",
    "unique_rooms_en = df['rooms_en'].unique()\n",
    "unique_procedure_area = df['procedure_area'].unique()\n",
    "unique_room_value = df['room_value'].unique()\n",
    "\n",
    "# Print each unique set of values\n",
    "print(\"Unique rooms_en values:\", unique_rooms_en)\n",
    "print(\"Unique procedure_area values:\", unique_procedure_area)\n",
    "print(\"Unique room_value values:\", unique_room_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d9a7c-dcdb-4a86-bbd2-ab572951da3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab12d31-1eae-44f8-8f9a-55d258750c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6451437d-80b1-40eb-8a0e-1add7ba48537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['transaction_id', 'instance_date', 'property_sub_type_en', 'rooms_en', 'nearest_metro_en', 'has_parking'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df13c0-ced2-4fb3-b837-1d471f2ca423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reg_type_en'] = df['reg_type_en'].replace('Existing Properties', 'Ready Property')\n",
    "df['reg_type_en'] = df['reg_type_en'].replace('Off-Plan Properties', 'Off-Plan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc196c28-abf6-4bbf-89a0-6cb39cdafc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd5ea47-b586-47d2-a867-e319e2ef5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import pickle\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "\n",
    "# List of categorical columns to encode\n",
    "categorical_columns = ['trans_group_en', 'property_type_en', 'property_usage_en', 'reg_type_en', 'area_name_en']\n",
    "\n",
    "# Initialize the binary encoder\n",
    "encoder = ce.BinaryEncoder(cols=categorical_columns)\n",
    "\n",
    "# Fit and transform to produce binary encoded data\n",
    "data = encoder.fit_transform(df.drop('actual_worth', axis=1))\n",
    "\n",
    "# Display the head of the DataFrame to see some of the encoded features\n",
    "\n",
    "with open('3encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(encoder, file)\n",
    "\n",
    "\n",
    "# Display the new structure of the DataFram\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48844f1d-c084-4b25-b521-6ef40e933bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf80cf2-d7a9-458c-8f8f-412ed40ee367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'X' are your features and 'y' is the target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, np.log(df['actual_worth']), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20c5aa-d921-473d-ba27-5c5cbbce4f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from scipy.stats import randint\n",
    "\n",
    "# param_dist = {\n",
    "#     'n_estimators': randint(100, 300),\n",
    "#     'max_depth': randint(10, 30)\n",
    "# }\n",
    "\n",
    "# random_search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42), param_distributions=param_dist, n_iter=10, cv=5, n_jobs=-1)\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# best_model = random_search.best_estimator_\n",
    "\n",
    "X_subset, _, y_subset, _ = train_test_split(X_train, y_train, train_size=0.1, random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 300),\n",
    "    'max_depth': randint(10, 30),\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 11)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42), param_distributions=param_dist, n_iter=10, cv=3, n_jobs=-1, verbose=2)\n",
    "random_search.fit(X_subset, y_subset)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best cross-validation score: \", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34ced63-1e83-4da5-bfec-d178f4bdb1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35f0c30-7e44-4770-b54c-74c4d5a0a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate R²\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R²:\", r2)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe19cb2-a071-4ac8-9a85-b124f4ae244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Prepare data\n",
    "X = data\n",
    "y = np.log(df['actual_worth'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "gbm = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.1, 0.05, 0.01],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=gbm, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_gbm = grid_search.best_estimator_\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = best_gbm.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Test Set RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15475331-46c6-415e-90e5-9be9035dd24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Initialize the final model with the best parameters\n",
    "final_model = GradientBoostingRegressor(learning_rate=0.1, max_depth=5, n_estimators=200, random_state=42)\n",
    "\n",
    "# Fit the model on the entire dataset\n",
    "X = data\n",
    "y = np.log(df['actual_worth'])\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa232c3c-c2c5-41d5-b86e-19fc4e363a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('2predictor.pkl','wb')\n",
    "pickle.dump(best_model,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b2812-58a0-4d55-b68e-3d48135f4786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c363b7d6-249c-4fa1-9268-d93ac6853eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744e9b9-affb-457a-bea6-5b6bca96bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ddd7a7-eb26-4fb6-b75c-8877fef0dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_property_sub_type_na(data):\n",
    "    # Fill NaN values in 'property_sub_type_en' using values from 'property_type_en'\n",
    "    data['property_sub_type_en'] = data.apply(\n",
    "        lambda row: row['property_type_en'] if pd.isna(row['property_sub_type_en']) else row['property_sub_type_en'],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# Apply the function to the dataset\n",
    "df = fill_property_sub_type_na(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c0be3-ebda-43b1-9aed-4d2a3987391b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d99a7f-99eb-4549-a237-66da51b91f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a11cb-96bb-43b7-8296-51c7303dcf76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0dfca-afa9-48ed-858b-1f2ef2be583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_type_frequency = df['property_sub_type_en'].value_counts()\n",
    "sub_type_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3cf9df-c498-4171-91fb-5ba446292151",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_frequency = df['property_type_en'].value_counts()\n",
    "type_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4dc8f-07e1-414f-a18a-99d5a8116f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['property_usage_en'].str.strip() != 'Hospitality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b44b444-2c4b-4a40-a8ee-866ca6c2329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_frequency = df['property_usage_en'].value_counts()\n",
    "usage_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad3d9f-8c97-4ab9-81ee-f887857691d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_frequency = df['rooms_en'].value_counts()\n",
    "rooms_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff3848-29e6-42f8-9674-a40b4b7654b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f1c12-ef53-428f-966f-510202addb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_frequency = df['rooms_en'].value_counts()\n",
    "rooms_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8758cd-3bfc-4942-a278-192761d31269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7703d8a5-e300-4608-bb7a-49c3bf53cf2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c977716-5e34-413c-86c3-0466a7c1f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_frequency = df['rooms_en'].value_counts()\n",
    "rooms_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc1a27-8c77-47a2-973d-e7ee6d7dec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_frequency = df['rooms_en'].value_counts()\n",
    "rooms_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ace81e-9f42-4cf0-91bc-a7e094451d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56291528-f0eb-4874-99b0-368e1482325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_type_en_frequency = df['property_type_en'].value_counts()\n",
    "property_type_en_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91964d2a-4892-4145-a6f3-35ac97732e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_procedure_by_room = df.groupby('rooms_en')['procedure_area'].mean()\n",
    "\n",
    "# Display the average procedure area for each room type\n",
    "print(\"Average procedure_area for each room type:\")\n",
    "print(average_procedure_by_room)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d603835-247c-48f5-a5ec-b93d4f120b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_procedure_by_room = df.groupby('rooms_en')['procedure_area'].mean().reset_index()\n",
    "\n",
    "# Rank the room types based on their average procedure_area (smallest gets 1)\n",
    "average_procedure_by_room['room_value'] = average_procedure_by_room['procedure_area'].rank(method='dense', ascending=True).astype(int)\n",
    "\n",
    "# Merge the ranked values back into the original dataframe\n",
    "df2 = pd.merge(df, average_procedure_by_room[['rooms_en', 'room_value']], on='rooms_en', how='left')\n",
    "\n",
    "# Display the dataframe with room values assigned\n",
    "df2[['rooms_en', 'procedure_area', 'room_value']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb9ef2d-9956-4cf7-b32b-2ce445a89a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba5005f-47a4-4988-99d4-790b992697d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af60f40-e0a5-4e4d-ab10-09c03235a67f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba30e34-68bb-4e0a-9e9a-4bbb5b02c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['transaction_id', 'instance_date', 'property_sub_type_en', 'rooms_en', 'nearest_metro_en', 'has_parking'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8094f1-3859-45b6-bc72-ec1229eefc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reg_type_en'] = df['reg_type_en'].replace('Existing Properties', 'Ready Property')\n",
    "df['reg_type_en'] = df['reg_type_en'].replace('Off-Plan Properties', 'Off-Plan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e162990c-1664-486a-9e2a-2e31767341d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d485cb-7850-4af2-be66-21e32beb6b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('Transaction2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce67fee-961f-4a17-a130-032e10a677ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_type_frequency = df['reg_type_en'].value_counts()\n",
    "reg_type_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a049f21-4b19-4bfc-85a6-f954c9d547ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d425ad9-14de-4180-9dc6-345da5df7bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import pickle\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "\n",
    "# List of categorical columns to encode\n",
    "categorical_columns = ['trans_group_en', 'property_type_en', 'property_usage_en', 'reg_type_en', 'area_name_en']\n",
    "\n",
    "# Initialize the binary encoder\n",
    "encoder = ce.BinaryEncoder(cols=categorical_columns)\n",
    "\n",
    "# Fit and transform to produce binary encoded data\n",
    "data = encoder.fit_transform(df.drop('actual_worth', axis=1))\n",
    "\n",
    "# Display the head of the DataFrame to see some of the encoded features\n",
    "\n",
    "with open('r_encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(encoder, file)\n",
    "\n",
    "\n",
    "# Display the new structure of the DataFram\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb338301-9328-4c9d-bf77-a9938be45aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da248de9-148e-4bf9-9b00-b6609c02ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'X' are your features and 'y' is the target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, np.log(df['actual_worth']), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9454d8ba-6147-4529-a729-06c78a3acf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from scipy.stats import randint\n",
    "\n",
    "# param_dist = {\n",
    "#     'n_estimators': randint(100, 300),\n",
    "#     'max_depth': randint(10, 30)\n",
    "# }\n",
    "\n",
    "# random_search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42), param_distributions=param_dist, n_iter=10, cv=5, n_jobs=-1)\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# best_model = random_search.best_estimator_\n",
    "\n",
    "X_subset, _, y_subset, _ = train_test_split(X_train, y_train, train_size=0.1, random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 300),\n",
    "    'max_depth': randint(10, 30),\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 11)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42), param_distributions=param_dist, n_iter=10, cv=3, n_jobs=-1, verbose=2)\n",
    "random_search.fit(X_subset, y_subset)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best cross-validation score: \", random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f136e-e3bd-407c-a141-6ff0bc1fa7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b00f064-47d7-4a4a-bc74-782834415f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate R²\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R²:\", r2)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d7da87-72e5-4e8e-b4bb-6f6b0f55592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('r_predictor.pkl','wb')\n",
    "pickle.dump(best_model,file)\n",
    "file.close()\n",
    "\n",
    "# dump(best_model, 'trans_encoder_j.joblib')\n",
    "\n",
    "# Save the model\n",
    "# dump(rf, 'trans_predictor_j.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f9a40f-befb-4b0d-ae35-4ef780d4f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # Prepare data\n",
    "# X = data\n",
    "# y = np.log(df2['actual_worth'])\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize the model\n",
    "# gbm = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# # Set up the parameter grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200],\n",
    "#     'learning_rate': [0.1, 0.05, 0.01],\n",
    "#     'max_depth': [3, 4, 5]\n",
    "# }\n",
    "\n",
    "# # Set up GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=gbm, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
    "\n",
    "# # Fit the model\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Best model\n",
    "# best_gbm = grid_search.best_estimator_\n",
    "\n",
    "# # Predict and evaluate\n",
    "# y_pred = best_gbm.predict(X_test)\n",
    "# rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "# print(\"Test Set RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec3c3d5-74fa-431a-a2ba-7879cf8b539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the model\n",
    "gbm = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'learning_rate': [0.1, 0.05, 0.01],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV with parallelization\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=gbm,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,  # Number of parameter settings sampled\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_gbm = random_search.best_estimator_\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = best_gbm.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Test Set RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c0b5ee-fa6e-4145-99dd-0aa98ed354c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Initialize the final model with the best parameters\n",
    "final_model = GradientBoostingRegressor(learning_rate=0.1, max_depth=5, n_estimators=200, random_state=42)\n",
    "\n",
    "# Fit the model on the entire dataset\n",
    "X = data\n",
    "y = np.log(df2['actual_worth'])\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4484371b-b77d-471c-8ef7-84786731371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Calculate R²\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R²:\", r2)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb598f-d224-400a-8785-05b341b951c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Calculate R²\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R²:\", r2)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed4fa62-0051-4e6c-beb7-2f0c4b16a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('q_predictor.pkl','wb')\n",
    "pickle.dump(best_model,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2062da4-38a3-4d9c-a1d4-481b33f46dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78449b39-174d-4e9d-b33f-e1ffa090d3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
